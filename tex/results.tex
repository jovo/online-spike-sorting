
\subsection{Data}

We used two different datasets to demonstrate the efficacy of \smug.  First, the ever popular, publicly available HC1 dataset %\footnote{http://crcns.org/data-sets/hc/hc-1/}
as described in \cite{Henze2000}.  We used the dataset d533101 that consisted of an extracellular tetrode and a single intracellular electrode.  The recording was made simultaneously on all electrodes and was set up such that the cell with the intracellular electrode was also recorded on the extracellular array implanted in the hippocampus of an anesthetized rat. The intracellular recording is relatively noiseless and gives nearly certain firing times of the intracellular neuron.  The extracellular recording contains the spike waveforms from the intracellular neuron as well as an unknown number of additional neurons.  The data is a 4-minute recording at a 10 kHz sampling rate.  

The second dataset comes from novel NeuroNexus devices implanted in the rat motor cortex.  The data was recorded at 32.5 kHz in freely-moving rats.  The first device we consider is a set of 3 channels of data shown in Fig.\ \ref{3dev}.  The neighboring electrode sites in these devices have 30 $\mu$m between electrode edges and 60 $\mu$m between electrode centers.  These devices are close enough that a locally-firing neuron could appear on multiple electrode sites \dec{(cite that paper on action potential overlap)}, so neighboring channels warrant joint processing.  The second device has 8-channels (as shown in Fig.\ \ref{8dev}), but is otherwise similar to the first.



For both datasets, we preprocessed with a high-pass filter at 800 Hz using a fourth order Butterworth filter before we analyzed the time series.  To get the PCA decomposition, we used the spikes detected with a threshold (three times the standard deviation of the noise above the mean) in the first five seconds and used the top three principal components.  The noise standard deviation was estimated both over the first five seconds of the recording as well as the entire recording, and the estimate was nearly identical.  Our results were also robust to minor variations in the choice of the number of principal components.  The autoregressive parameters were estimated by using lag-1 autocorrelation on the same set of data.  For the multichannel algorithms we estimate the covariance between channels and normalize by our noise variance estimate.

Each algorithm gives a clustering of the detected spikes.  In this dataset, we only have a partial ground truth, so we can only verify accuracy for the neuron with the intracellular (IC) recording.  In these experiments, we define a detected spike to be an IC spike if the IC recording has a spike within 0.5 milliseconds (ms) of the detected spike in the extracellular recording.  We define the cluster with the greatest number of intracellular spikes as a the ``IC cluster''.   We refer to these data as ``partial ground truth data'', because we know the ground truth spike times for one of the neurons, but not all the others.  




\subsection{Bake-off!}

We compare a number of variants of \smug, as well as several previously proposed methods, as described below.  The vanilla version of \smug\ operates on a single channel with colored noise.  When using multiple channels, we append an ``\sct{M}'' to obtain \sct{M}\smug.  When we model the mean of the waveforms as an auto-regressive process, we ``post-pend'' to obtain \smug\sct{R}.  
We compare these variants of \smug\ to Gaussian mixture models and k-means with N components (\sct{Gmm-N} and \sct{K-N}, respectively), where \sct{N} indicates the number of components.  Finally, we include a Focus Mixture Model (\sct{Fmm}) \cite{??}, a recently proposed Bayesian generative model with state-of-the-art performance.  Only \smug\ methods were online as we desired to compare to the state-of-the-art \emph{batch} algorithms which use all the data. 
% could not find any previous code available for online spike sorting, despite a small literature on the topic \cite{??}.  
Note that \smug\ algorithms used a dictionary learned from the first five seconds of data, whereas all other algorithms used a dictionary learned from the entire data set.  In either case, the dictionary consisted of the first five principal components of the matrix consisting of all waveforms from the thresholded voltage traces.  Supplementary Fig.\ \ref{fig:waveforms} shows the two different dictionaries and the relative fraction of variance explained.

% 
% 
The single-channel experiments were all run on channel 2 (the results were nearly identical for all channels).  The spike detections for the offline methods used a threshold of three times the noise standard deviation \cite{Lewicki} (unless stated otherwise), and windowed at a size $L=30$.  For multichannel data, we concatenated the $M$ channels for each waveform to obtain a $M\times L$-dimensional vector.
%, and PCA was used to reduce the space to $K$=5 for the experiments. 

% \subsection{Results}

% The online algorithms were all run with weakly informative parameters (\dec{add parameters once I get vinayak's notation}). The parameters were insensitive to minor changes.  Running time in unoptimized MATLAB code for 4 minutes of data was 31s was a single channel and 3 minutes for all 4 channels on a 3.2 GHz Intel Core i5 machine with 6 GB of memory.

The online algorithms were all run with weakly informative parameters, namely  $\mb{\mu}_0=\mb{0}$ $,\lambda_0=0.1,\bW=10\bI$, and $\nu=1$ ($\bI$ is the identity matrix).  
For the autoregressive process, we set $\bB=(1-\mathsf{exp}(-2\times 10^{-6}))\bI$ and $r_t\sim\mathsf{N}(0,\mathsf{exp}(-4\times 10^{-6})\bI$.  $\alpha$ was set to $0.1$. The parameters were insensitive to minor changes.  Running time in unoptimized MATLAB code for 4 minutes of data was 31 seconds for a single channel and 3 minutes for all 4 channels on a 3.2 GHz Intel Core i5 machine with 6 GB of memory (see Supplementary Fig.\ \ref{fig:timing} for details).

\subsection{Performance on partial ground truth data}



The main empirical result of our contribution is that all variants of \smug\ detect more true positives with fewer false positives than any of the other algorithms on the partial ground truth data (see Fig.\ \ref{hc1res}).  
Our improved sensitivity and specificity is \emph{despite} that \smug\ is fully online, whereas all the algorithms that we compare to are batch algorithms using all data for all spikes.   Note that all the comparison algorithms pre-process the data via thresholding at some constant (which we set to three standard deviations above the mean).  To assess the extent to which performance of \smug\ is due to \emph{not} thresholding, we implement \sct{Fake}-\smug, which thresholds the data.  Indeed, \sct{Fake}-\smug's performance is much like that of the batch algorithms.  To get uncertainty estimates, we split the data into ten random two minute segments and repeat this analysis. The results are qualitatively similar (see Supplementary Fig.\ \ref{sfig:hc1res}).


One possible explanation for the relatively poor performance of the batch algorithms as compared to \smug\ is a poor choice of the important---but often overlooked---threshold parameter.  The right panel of Fig.\ \ref{hc1res} shows the receiver operating characteristic (ROC) curve for the k-means algorithms as well as \smug\ and \sct{M}\smug\ (where \sct{M} indicates multichannel, see below for detail).  Although we typically run \smug\ without tuning parameters, the prior on $\Lambda$ sets the expected number of spikes, which we can vary in a kind of ``empirical Bayes'' strategy.  Indeed, the \smug\ curves are fully above the batch curves for all thresholds and priors, suggesting that regardless of which threshold one chooses for pre-processing, \smug\ always does better on these data than all the competitor algorithms.  Moreover, \smug\ which infers $\Lambda$ from the data (indicated by an \jovo{@dec - what symbol did you use here?}) is \jovo{@dec - does how good?}.

The above analysis suggests \smug's ability to detect signals more reliably than thresholding contributes to its success.  In the following, we provide evidence suggesting how several of \smug's key features are fundamental to this improvement.
%
\begin{center}
\begin{SCfigure}[3]
	\includegraphics[width=0.28\textwidth]{../figs/truefalsepositive.pdf}
	\includegraphics[width=0.3\textwidth]{../figs/new/icroc.pdf}
% \begin{subfigure}[b]{.49\textwidth}
% \centering
% \includegraphics[width=\textwidth]{../figs/truefalsepositive.pdf}
% \caption{}
% \label{hc1res}
% \end{subfigure}
% \begin{subfigure}[b]{.49\textwidth}
% \includegraphics[width=\textwidth]{../figs/new/icroc.pdf}
% \caption{}
% \label{fig:roc}
% \end{subfigure}
\caption{\smug\ achieves improved sensitivity and specificity over all competing methods on partial ground truth data. % (where true positives from one neuron are known from intracellular recordings).  
(a) True positive and false positive rates for all variants of \smug\ and several competing 
% state-of-the-art \emph{batch} 
algorithms.  
(b) ROC curves demonstrating that \smug\ outperforms all competitor algorithms, regardless of threshold (\jovo{*} indicates learning $\Lambda$ from the data).}
\end{SCfigure}
\end{center}
% 
% 
% 
\vspace{-10pt}
\subsection{Overlapping Spike Detection}



A putative reason for the improved sensitivity and specificity of \smug\ over other algorithms is its ability to detect overlapping spikes.   When spikes overlap, although the result can accurately be modeled as a linear sum in voltage space, the resulting waveform often does not appear in any cluster in PC space (see \ref{Pillow2013}).  However, our online approach can readily find such overlapping spikes.  Fig.\ \ref{fig:overlapping} (top left panel) shows one example of 135 examples where \smug\ believed that multiple waveforms were overlapping (see Supplementary materials for plots of the remaining 134 examples).  
Note that even though the waveform peaks are approximately 1 ms from one another, thresholding algorithms do not pick up these spikes, because they look different in PC space. \jovo{@dec - can we show that in the Supplement?}.

Indeed, by virtue of estimating the presence of multiple spikes, the residual squared error between the expected voltage and observed voltage shrinks for this snippet (bottom left).  The right panel of Fig.\ \ref{fig:overlapping} shows the density of the residual errors for all putative overlapping spikes.  The mass of this density is significantly smaller than the mass of the other scenarios.  Of all the true spikes that we detect, 37 of them we believe to be overlapping.  Thus, while it seems detecting overlapping spikes helps, it does not fully explain the improvements over the competitor algorithms.
\jovo{@jovo - add an actual statistical test test.} 


% It is possible for action potentials to fire close to simultaneously so that a given window would have 2 or move action potent ions.  It is possible for the algorithm to detect and fit overlapping spikes as they come in.  Out of the 3593 spikes detected by the algorithm, there are 124 pairs of overlapping spikes within 1 ms of one another (3.45\%).  An example of an overlapping waveform is shown in Fig.\ \ref{overlapping}.


\begin{center}
\begin{SCfigure}[3]
\includegraphics[width=.28\textwidth]{../figs/alloverlappingspikes/olspike3}
\includegraphics[width=.28\textwidth]{../figs/overlappingstatv2.pdf}
% \begin{subfigure}[b]{.3\textwidth}
% \includegraphics[width=\textwidth]{../figs/alloverlappingspikes/olspike3}
% \caption{}
% \label{fig:overlapping}
% \end{subfigure}
% \begin{subfigure}[b]{.3\textwidth}
% \includegraphics[width=\textwidth]{../figs/overlappingstatv2.pdf}
% \caption{asdf}
% \label{fig:resid}
% \end{subfigure}
\caption{\smug\ can detect multiple overlapping waveforms (Top Left) The observed voltage (solid black), MAP waveform 1 (red), MAP waveform 2 (blue), and expected waveform from the sum (dashed-black). (Bottom Left) Residuals from same example snippet, demonstrating a clear improvement in residuals.  (c) {Histogram of residuals for all putative overlapping examples.}} \label{fig:overlapping}
\end{SCfigure}
\end{center}


\vspace{-10pt}
\subsection{Time-Varying Waveform Adaptation} \label{sub:adapt}


As as been demonstrated previously \cite{calabrese2011kalman}, the waveform shape of a neuron may change over time.  The mean waveform over time for the intracellular neuron is shown in Fig.\ \ref{evohc1}.  Clearly, the mean waveform is changing over time.  Moreover, these changes are reflected in the principal component space (Fig.\ \ref{fig:clusterevo}).  We therefore compared means and variances \smug\ with \smug\sct{R}, which models the mean of the dictionary weights via an auto-regressive process.  Fig.\ \ref{fig:AR} shows that the auto-regressive model for the mean dictionary weights yields a time-varying posterior (top), whereas the static prior yields a constant posterior mean with increasing posterior marginal variances (bottom).  More precisely, the mean of the posterior standard deviations for the time-varying prior is about half of that for the static prior's posteriors. 
Indeed, the \smug\sct{R} yields 11 more true detections than \smug.
 
% \jovo{plot 3 ARs on top of each other, and also plot 3 stationary on top of each other.}
% \jovo{AR: mean 0.0037  std  0.0038
   % other: mean 0.0077  std  0.0071}

\begin{center}
\begin{figure}
\begin{subfigure}[b]{.33\textwidth}
\includegraphics[width=\textwidth]{../figs/evohc1}
\caption{}
\label{evohc1}
\end{subfigure}
\begin{subfigure}[b]{.33\textwidth}
\includegraphics[width=\textwidth]{../figs/new/clusterevo.pdf}
\caption{}
\label{fig:clusterevo}
\end{subfigure}
\begin{subfigure}[b]{.33\textwidth}
\includegraphics[width=\textwidth]{../figs/new/ARvsStationary.pdf}
\caption{}
\label{fig:AR}
\end{subfigure}
\caption{
The IC waveform changes over time, which our posterior parameters track. 
(a) Mean IC waveforms over time.  Each colored line represents the mean of the waveform averaged over 24 seconds with color denoting the time interval.  This neuron decreases in amplitude over the period of the recording. 
(b) The same waveforms plotted in PC space still captures the temporal variance.
(c) The mean and standard deviation of the waveforms at three time points for the auto-regressive prior on the mean waveform (top) and static prior (bottom). While the auto-regressive prior admits adaptation to the time-varying mean, the posterior of the static prior simply increases its variance.  
}
\end{figure}
\end{center}

\vspace{-10pt}
\subsection{Multielectrode Array} \label{sub:multi}
% \vspace{-5pt}


Another key feature of \smug\ is its ability to incorporate multiple channels.  For the HC1 data, \sct{M}\smug\ (the multielectrode variant) achieved \jovo{??} more true positives, while only missing an additional \jovo{??} spikes (see Fig.\ \ref{hc1res}).  We further evaluate the impact of multiple channels using both a three channel Michigan shank (Fig.\ \ref{3dev}). In Fig.\ \ref{ex31} and\ref{ex32} we show the top two most prevalent waveforms from these data across the three electrodes.  If only the third electrode would have been used, these two waveforms would not be distinct (as evidenced by their substantial overlap in PC space upon using only the third channel).  This suggests that by borrowing strength across electrodes, we obtain improved detection accuracy. Supplementary Fig.\ \ref{sfig:8} shows a similar plot for the eight channel data.  


% In the tetrode case the waveform undoubtedly appears on all channels at once; it is possible to concatenate the channels to jointly process the data \cite{wood2009}.  When the action potential will only appear on a subset of channels it is nice to allow the action potential to vary in a low-dimensional subset in each of the channels instead of a low-dimensional subset over all the channels. \cite{Prentice2011}


 % The top 2 clusters found in the first 10 minutes of data on the 3-channel device are shown in Figures \ref{ex31}, \ref{ex32}.  The waveform in channel 3 is very similar for the waveforms in Fig.\\ref{ex31} and \ref{ex32}, and would be difficult to separate if we were analyzing each channel individually; the representation of those two clusters in PCA space on channel 3 is shown in Fig.\\ref{chpca}.  We gain the ability to distinguish the waveforms by looking at all the channels simultaneously.  The top 3 clusters found in the 8-channel device can be found in Figures \ref{ex81}, \ref{ex82}, and \ref{ex83}.



\begin{center}
\begin{figure}[h!]
\begin{subfigure}[b]{.12\textwidth}
\includegraphics[width=1\textwidth]{../figs/3dev}
\caption{}
\label{3dev}
\end{subfigure}
\begin{subfigure}[b]{.28\textwidth}
\includegraphics[width=\textwidth]{../figs/3devim/clus1}
\caption{}
\label{ex31}
\end{subfigure}
\begin{subfigure}[b]{.28\textwidth}
\includegraphics[width=\textwidth]{../figs/3devim/clus2}
\caption{}
\label{ex32}
\end{subfigure}
\begin{subfigure}[b]{.28\textwidth}
\includegraphics[width=\textwidth]{../figs/new/3chpca}
\caption{}
\label{3chpca}
\end{subfigure}
% \caption{}
% \end{figure}
% \end{center}
% \begin{center}
% \begin{figure}[h!]
% \begin{subfigure}[b]{.12\textwidth}
% \includegraphics[width=0.8\textwidth]{../figs/8dev}
% \caption{}
% \label{8dev}
% \end{subfigure}
% \begin{subfigure}[b]{.28\textwidth}
% \includegraphics[width=\textwidth]{../figs/8devim/clus3}
% \caption{}
% \label{ex81}
% \end{subfigure}
% \begin{subfigure}[b]{.28\textwidth}
% \includegraphics[width=\textwidth]{../figs/8devim/clus9}
% \caption{}
% \label{ex82}
% \end{subfigure}
% \begin{subfigure}[b]{.28\textwidth}
% \includegraphics[width=\textwidth]{../figs/8devim/clus6}
% \caption{}
% \label{ex83}
% \end{subfigure}
\caption{
(a) Three electrode device showing local proximity of electrodes with channel indexes in large, red numbers. (b,c) Top 2 most prevalent waveforms.  Each waveform shape is 2ms long.   Note in (a) we have a waveform that appears on both channel 2 and channel 3, whereas in (b) the waveform only appears in channel 3.  If only channel 3 was used, it would be difficult to separate the waveform in (a) and (b), as is demonstrated in Fig.\ (d) by the representation of detected spikes on the 3rd channel in PCA space.
}
\end{figure}
\end{center}



\vspace{-10pt}
\subsection{Limitations of Dictionary-Based Techniques} \label{sub:template}
\vspace{-5pt}


\begin{center}
\begin{figure}[h!]
\begin{subfigure}[b]{.33\textwidth}
\includegraphics[width=\textwidth]{../figs/new/ICclusteroldpca.pdf}
\caption{}
\label{fig:ICold}
\end{subfigure}
\begin{subfigure}[b]{.33\textwidth}
\includegraphics[width=\textwidth]{../figs/new/ICclusternewpca.pdf}
\caption{}
\label{fig:ICnew}
\end{subfigure}
\begin{subfigure}[b]{.33\textwidth}
\includegraphics[width=\textwidth]{../figs/IntracellularTrueFalsePositivesv2}
\caption{}
\label{truewaveforms}
\end{subfigure}
\caption{Template matching.
(c) Errorbar plots of the true positives and the false positives in the IC cluster.  While the false positives have slightly more variability, the mean shape for the false positives and the true positives is nearly identical.  The true misses have a significantly lower amplitude as well as high variability. 
} \label{fig:IC-PCA}
\end{figure}
\end{center}














