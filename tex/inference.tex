\newcommand{\tx}{\tilde{x}}
\newcommand{\bY}{\mathbf{Y}}

\begin{algorithm}
\caption{Generative mechanism for the multi-electrode, nonstationary, discrete-time process}\label{alg:gen_proc}
\begin{tabular}{p{1.2cm}p{12.4cm}}
Input:&  The number of bins $T$, and the bin-width $\Delta$\\
  & The DP concentration parameter $\alpha$, and the hyperparameters of the base-measure $H(\cdot)$\\ 
 & Decay parameter of the neuron parameter \\
Output:& An $H$-by-$T$ matrix $\bX$ of multielectrode recordings. % defined by a set of state and time pairs.
\end{tabular}
\begin{algorithmic}[1]
\State Initialize the number of clusters $C = 0$.
\State Draw the overall spiking rate $R \sim \text{Gamma}(1,\alpha)$.
%\State Set $A_{s_i}(\tau) = \sum_j A_{s_i,j} (\tau)$ and define $u_{s_i}(\tau) \ge A_{s_i}(\tau) \forall \tau$. \label{alg:loop}
%\State Let $\tau_o = (w_{i} - l_i)$. \label{alg:smjp_loop}
\For{$t \le T$}
\State Sample $z_t \sim \text{Bernoulli}(R\Delta)$. $z_t = 1$ indicates a spike in bin $t$.
\If{$z_t = 1$}   \label{enum:thin}
  \State Set $\mu_t$, assigning the spike to neuron $i$, with
\begin{align}
  P({\nu_t} = i) & \propto 
  \begin{cases}
   n_i \quad i \in \{1,\cdots, C\} \\
   \alpha \quad\ i = C + 1 \\
  \end{cases}
\end{align}
\State If{ $\nu_t = C + 1$}, set $\theta^*_{C+1} \sim H(\cdot)$, and increment $C$.
\State Set $\theta_t = \theta^*_{\nu_t}$.
\State $\bY \sim \mathcal{N}(\mu_t, \Sigma_t \otimes K)$
\State $\bx^h_{t:t+L} = A\by^h$
\EndIf

\State Update the cluster parameters following the AR process: $$\mu^*_i = \mathbf{A} \mu^*_i + r_i \quad i \in \{1, \cdots, C\}$$
\EndFor
\State $\bX = \bX + \mathbf{\epsilon}$
\end{algorithmic}
\end{algorithm}


We now address the problem of posterior inference over the latent variables gives the matrix $\bX$ of multielectrode recordings. Unsurprisingly, exact 
inference is intractable, and we have to resort to approximating the posterior distribution.
There exists a vast literature on approximate inference for Bayesian nonparametric models, especially so for models based on the Dirichlet process.
Traditional approaches are sampling-based, typically involving Markov chain Monte Carlo techniques (see eg.\ \citep{Nea2000, IshJam2001}), 
and recently there has also been work on constructing deterministic approximations to the intractable posterior (eg.\ \citep{BleJor2006, MinGha2003}).
Our problem is even more challenging because of two factors. The first is the convolutional nature of our observation process, where at each time,
we observe a function of the previous observations drawn from a DP mixture model. This is in contrast to the usual situation where one directly observes 
the DPMM outputs themselves.
The second complication is a computational requirement: typical inference schemes are batch methods that are slow and computationally expensive. 
Our ultimate goal, on the other hand, is to perform inference in real time, making these approaches are unsuitable for our purposes.

With the latter objective in mind, we develop an online algorithm for posterior inference. Our algorithm is based on 
\citep{WangDun2009}, though that work was concerned with the usual case of i.i.d.\ observations from a DPMM. We generalize this algorithm to our 
observation process, and also to account for the time-evolution of the cluster parameters.

At a high level, at time $t$, our algorithm maintains the set of times of the spikes it has inferred from the observations until time $t$. It also maintains
the identities of the neurons that it assigned each of these spikes to, as well as the weight vectors determining the shapes of the associated spike 
waveforms. In addition to these point estimates, the algorithm also maintains a set of posterior distributions $q_{it}(\theta^*_i)$ where $i$ spans over the
set of neurons associated with the spikes seen so far. Let the number of unique neurons observed at time $t$ be $C_t$, so that $i$ varies from $1$ to $C_t$.
For each $i$, $q_{it}(\theta^*_i)$ approximates the distribution over the parameters 
$\theta_i^* \equiv (\mu_i^*, \Sigma_i^*)$ of neuron $i$ given the observations until time $t$. 

Having identified the location and shape of spikes from earlier times, we can calculate their contribution to the recording $x_{t+1}$ at time $t+1$.
We subtract this term from $x_{t+1}$, and treat the residual $\tx_{t+1}$ as an observation from a DP mixture model.
Given this residual, our algorithm then makes a hard decision about whether or not this was produced by an underlying spike, what neuron that spike belongs 
to (one of the earlier neurons or a new neuron), and what the shape of the associated spike waveform is. The latter is used to calculate
$q_{i,t+1}(\theta^*_i)$, the new distribution over neuron parameters at time $t+1$. Our algorithm proceeds recursively in this manner. 


We provide a more detailed discussion in the following.
Recall that the basis functions $\bA_i$, and thus all spike waveforms, span $L$ time bins. 
Let $z_t$ indicate whether or not a spike is present at time $t$, with $\by_t$ giving its shape, and $\nu_t$ is associated neuron. 
The residual at time $t$ is then given by
\begin{align}
  \tx_t = x_t - \sum_{i=1}^L \bA\by_{t-i} \label{eq:resid}
\end{align}
Given this residual, the first step is to decide whether or not there is a spike underlying this residual.
By Bayes' rule,
\begin{align}
  P(z_t = 1 | \tx_t)  &\propto P(z_t = 1, \tx_t) = \sum_{\nu_t = 1}^{C_{t-1}+1} P(\tx_t, {\nu_t} | z_t = 1) P(z_t = 1) \\
\intertext{Here, $C_{t-1}$ is the number of unique neurons underlying the observations before time $t$. Letting $n_i$ be the number of spikes from neuron 
$i$, we have from the Chinese restaurant process that}
  P({\nu_t} = i | z_t = 1) & \propto 
  \begin{cases}
   n_i \quad i \in \{1,\cdots, C_{t-1}\} \\
   \alpha \quad\ i = C_{t-1} + 1 \\
  \end{cases}  \label{eq:crp_marg}\\
\intertext{On the other hand,}
  P(\tx_t | {\nu_t = i} , z_t = 1) &= \int_{\Theta} P(\tx_t | \theta_t) q_{it} (\theta_t) \dd \theta_t  \label{eq:norm_nw}
\end{align}
Recall that  $P(\tx_t | \theta_t)$ is just the normal distribution with mean $\mu_t$ and variance $\theta_t$. We let $q_{it}(\cdot)$ be the normal-Wishart
distribution. % with parameters 
We can then evaluate integral \eqref{eq:norm_nw}, and then summation \eqref{eq:crp_marg} to calculate $P(z_t = 1 | \tx_t)$. 
If this exceeds a threshold of $0.5$ we decide that there is a spike present at time $t$, otherwise, we set $z_t = 0$.
Note that we make this decision after marginalizing over all possible cluster assignments and all values of the weight vector $\by_t$.
In the event that we decide that a spike is present , we simplify matters collapsing these parameters, and the spike the neuron and weight-vector
with highest posterior probability. Given these two, we update the posterior distribution over parameters of cluster $\nu_t$, thereby obtaining
$q_{i,t+1}$.
